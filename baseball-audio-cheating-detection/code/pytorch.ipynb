{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchviz import make_dot\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import shap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "images = np.load('image_file.npy')\n",
    "meta = np.load('meta_file.npy')\n",
    "df = pd.read_csv('processed_pitch_table.csv')\n",
    "\n",
    "train_dataset = TensorDataset(torch.Tensor(images[:9000]/255),\n",
    "                        torch.Tensor(meta[:9000]),\n",
    "                        torch.Tensor(df.label.values[:9000]))\n",
    "\n",
    "\n",
    "test_dataset = TensorDataset(torch.Tensor(images[9000:]/255),\n",
    "                        torch.Tensor(meta[9000:]),\n",
    "                        torch.Tensor(df.label.values[9000:]))\n",
    "\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=128)#, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=128)#, shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "class BaseballCNN(nn.Module):\n",
    "    def __init__(self,filters=32,dropout=0.1,nodes=32):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(1, filters, 3)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.drop1 = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.conv2 = nn.Conv2d(filters, filters, 3)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.drop2 = nn.Dropout(p=dropout)\n",
    "        \n",
    "        self.conv3 = nn.Conv2d(filters, filters, 3)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        \n",
    "        self.linear_image = nn.Linear(filters* 11* 14,nodes-4)\n",
    "        self.linear_meta = nn.Linear(20,4)\n",
    "        self.drop3 = nn.Dropout(dropout)\n",
    "        \n",
    "        self.linear2 = nn.Linear(nodes,nodes) \n",
    "        self.drop4 = nn.Dropout(dropout)\n",
    "        self.linear3 = nn.Linear(nodes,1)\n",
    "        \n",
    "    def forward(self, x_image,x_meta):\n",
    "        \n",
    "        x_image = F.relu(self.conv1(x_image))\n",
    "        x_image = self.pool1(x_image)\n",
    "        x_image = self.drop1(x_image)\n",
    "        # print(x_image.shape)\n",
    "        x_image = F.relu(self.conv2(x_image))\n",
    "        x_image = self.pool2(x_image)\n",
    "        x_image = self.drop2(x_image)\n",
    "\n",
    "        x_image = F.relu(self.conv3(x_image))\n",
    "        # print(x_image.shape)\n",
    "        x_image = self.pool3(x_image)\n",
    "        # print(x_image.shape)\n",
    "        # x_image = x_image.view(-1, 128 * 154)\n",
    "        x_image = torch.flatten(x_image,1)\n",
    "        # print(x_image.shape)\n",
    "        x_image = self.linear_image(x_image)\n",
    "        # print(x_image.shape)\n",
    "        # print()\n",
    "        x_meta = self.linear_meta(x_meta)\n",
    "        # print(x_image.shape,x_meta.shape)\n",
    "        x = torch.cat((x_image,x_meta),1)\n",
    "        # x = self.linear3(self.drop4(self.linear2(x)))\n",
    "        x= torch.sigmoid(self.linear3(self.drop4(self.linear2(x))))\n",
    "        # x = F.softmax(self.linear3(self.drop4(self.linear2(x))),dim=0)\n",
    "        return x\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = 32\n",
    "\n",
    "dropout = 0.1\n",
    "nodes = 32\n",
    "num_epochs = 40#60\n",
    "# learning_rate = 0.0005 \n",
    "learning_rate = 0.0001\n",
    "device = torch.device('mps')\n",
    "\n",
    "\n",
    "\n",
    "# Loss and optimizer\n",
    "criterion = nn.BCELoss()\n",
    "\n",
    "model = BaseballCNN(filters,dropout,nodes).to(device)\n",
    "model.train()\n",
    "# print(f'filters: {filters} dropout: {dropout} nodes: {nodes}')\n",
    "# Device configuration\n",
    "\n",
    "# Loss and optimizer\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)  \n",
    "\n",
    "train_losses=[]\n",
    "test_losses=[]\n",
    "test_acc=[]\n",
    "train_acc=[]\n",
    "# Train the model\n",
    "patience = 5\n",
    "lowest_loss = 1\n",
    "epochs_without_improvement = 0\n",
    "for epoch in range(num_epochs):\n",
    "    print(epoch)\n",
    "    epoch_train_losses=0\n",
    "    epoch_test_losses=0\n",
    "    epoch_train_acc=0\n",
    "    epoch_test_acc=0\n",
    "    model.train()\n",
    "    for i, (image_batch,meta_batch, y_batch) in enumerate(train_loader):  \n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        image_batch = image_batch.to(device)\n",
    "        meta_batch  = meta_batch.to(device)\n",
    "        y_batch     = y_batch.to(device)\n",
    "        \n",
    "        # Forward pass and loss calculation\n",
    "        outputs = model(image_batch,meta_batch)\n",
    "        loss = criterion(outputs.squeeze(1), y_batch)\n",
    "\n",
    "        # Backward and optimize\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Validation Loop \n",
    "\n",
    "    with torch.no_grad(): \n",
    "        model.eval() \n",
    "        for i, (image_batch,meta_batch, y_batch) in enumerate(test_loader): \n",
    "            image_batch = image_batch.to(device)\n",
    "            meta_batch  = meta_batch.to(device)\n",
    "            y_batch     = y_batch.to(device)\n",
    "            outputs = model(image_batch,meta_batch)\n",
    "            loss = criterion(outputs.squeeze(1), y_batch)\n",
    "            epoch_test_losses+=outputs.shape[0]*loss.item()\n",
    "            epoch_test_acc += (((outputs[:,0].cpu().detach().numpy()>0.5)*1==y_batch.cpu().detach().numpy())*1).sum()\n",
    "\n",
    "        for i, (image_batch,meta_batch, y_batch) in enumerate(train_loader): \n",
    "            image_batch = image_batch.to(device)\n",
    "            meta_batch  = meta_batch.to(device)\n",
    "            y_batch     = y_batch.to(device)\n",
    "            outputs = model(image_batch,meta_batch)\n",
    "            loss = criterion(outputs.squeeze(1), y_batch)\n",
    "            epoch_train_losses+=outputs.shape[0]*loss.item()\n",
    "            epoch_train_acc += (((outputs[:,0].cpu().detach().numpy()>0.5)*1==y_batch.cpu().detach().numpy())*1).sum()\n",
    "\n",
    "\n",
    "    # print(f'Validation Loss: {running_val_loss/len(test_loader):.4f}')\n",
    "\n",
    "    test_losses += [epoch_test_losses/len(test_dataset)]\n",
    "    test_acc += [epoch_test_acc/len(test_dataset)]\n",
    "    train_losses += [epoch_train_losses/len(train_dataset)]\n",
    "    train_acc += [epoch_train_acc/len(train_dataset)]\n",
    "\n",
    "    if (test_losses[-1] < lowest_loss) or (epoch < 10):\n",
    "        lowest_loss = test_losses[-1]\n",
    "        epochs_without_improvement = 0\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement > patience:\n",
    "        print('Early stopping')\n",
    "        break\n",
    "\n",
    "    # Additional information\n",
    "    EPOCH = epoch\n",
    "    PATH = f\"model/model_{EPOCH}.pt\"\n",
    "\n",
    "    torch.save({\n",
    "                'epoch': EPOCH,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': test_losses[-1],\n",
    "                }, PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "  \n",
    "\n",
    "\n",
    "\n",
    "epochs=len(train_losses)\n",
    "\n",
    "fig = plt.figure(1, (7,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.plot(np.arange(1,epochs+1),train_losses,label='train')\n",
    "ax.plot(np.arange(1,epochs+1),test_losses,label='test')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('loss')\n",
    "ax.legend()\n",
    "ax.set_title('Model Loss')\n",
    "ax.grid()\n",
    "plt.savefig('cnn_loss.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.ticker as mtick\n",
    "from matplotlib.ticker import PercentFormatter\n",
    "  \n",
    "epochs=len(train_losses)\n",
    "\n",
    "fig = plt.figure(1, (7,5))\n",
    "ax = fig.add_subplot(1,1,1)\n",
    "\n",
    "ax.plot(np.arange(1,epochs+1),train_acc,label='train')\n",
    "ax.plot(np.arange(1,epochs+1),test_acc,label='test')\n",
    "ax.plot([1,epoch+1],[0.6569541217989322,0.6569541217989322],label='upper bound',ls='--',color='grey')\n",
    "ax.plot([1,epoch+1],[0.5535245679124061,0.5535245679124061],label='baseline',ls='--',color='black')\n",
    "ax.set_xlabel('epoch')\n",
    "ax.set_ylabel('accuracy')\n",
    "ax.legend()\n",
    "ax.set_title('Model Accuracy')\n",
    "ax.grid()\n",
    "ax.yaxis.set_major_formatter(mtick.PercentFormatter(1)) \n",
    "plt.savefig('cnn_acc.png')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_batch,meta_batch, y_batch = test_dataset[:2000]\n",
    "image_batch2,meta_batch2, y_batch2 = test_dataset[-500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# since shuffle=True, this is a random sample of test data\n",
    "model.to('cpu')\n",
    "background = [image_batch2.to('cpu'),meta_batch2.to('cpu')]\n",
    "test_images = [image_batch.to('cpu'),meta_batch.to('cpu')]\n",
    "\n",
    "e = shap.DeepExplainer(model, background)\n",
    "shap_values = e.shap_values(test_images)\n",
    "\n",
    "\n",
    "shap_numpy = [np.swapaxes(s, 0, 2) for s in shap_values[0]]\n",
    "test_numpy = np.swapaxes(test_images[0].numpy(), 1, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top = pd.DataFrame({'p':p[:2000]}).sort_values('p',ascending=False).head(100).index\n",
    "for i in top:\n",
    "# plot the feature attributions\n",
    "    fig = shap.image_plot(shap_numpy[i],image_batch[i].numpy().squeeze(0).T,show=False)\n",
    "    plt.savefig(f'cnn_shap_{i}.png')\n",
    "    plt.close('all')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
